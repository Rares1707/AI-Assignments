{"cells":[{"cell_type":"markdown","metadata":{},"source":["# REGRESSION\n","\n","Consider the following database from he UCI databases repository https://archive.ics.uci.edu/dataset/29/computer+hardware\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T19:26:47.673761Z","iopub.status.busy":"2024-05-08T19:26:47.673407Z","iopub.status.idle":"2024-05-08T19:27:04.748947Z","shell.execute_reply":"2024-05-08T19:27:04.747409Z","shell.execute_reply.started":"2024-05-08T19:26:47.673733Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ucimlrepo\n","  Downloading ucimlrepo-0.0.6-py3-none-any.whl.metadata (5.3 kB)\n","Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n","Installing collected packages: ucimlrepo\n","Successfully installed ucimlrepo-0.0.6\n"]}],"source":["# install the  b package\n","\n","!pip install ucimlrepo"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T20:14:17.740457Z","iopub.status.busy":"2024-05-08T20:14:17.740077Z","iopub.status.idle":"2024-05-08T20:14:17.994261Z","shell.execute_reply":"2024-05-08T20:14:17.992881Z","shell.execute_reply.started":"2024-05-08T20:14:17.740430Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["VendorName    object\n","ModelName     object\n","MYCT           int64\n","MMIN           int64\n","MMAX           int64\n","CACH           int64\n","CHMIN          int64\n","CHMAX          int64\n","PRP            int64\n","ERP            int64\n","dtype: object\n"]}],"source":["from ucimlrepo import fetch_ucirepo \n","\n","# fetch dataset \n","computer_hardware = fetch_ucirepo(id=29) \n","  \n","# data (as pandas dataframes) \n","df = computer_hardware.data.features\n","df.dropna(inplace=True)\n","\n","X = df.drop(['PRP', 'ERP'], axis=1)\n","y = df[['PRP', 'ERP']]\n","print(df.dtypes)\n","\n","le = LabelEncoder()\n","X['VendorName'] = le.fit_transform(X['VendorName'])\n","X['ModelName'] = le.fit_transform(X['ModelName'])\n","\n","# metadata \n","#print(computer_hardware.metadata) \n","  \n","# variable information \n","#print(computer_hardware.variables) "]},{"cell_type":"markdown","metadata":{},"source":["The content of the Database are:\n","\n","Features\n","1. vendor name: 30 \n","      (adviser, amdahl,apollo, basf, bti, burroughs, c.r.d, cambex, cdc, dec, \n","       dg, formation, four-phase, gould, honeywell, hp, ibm, ipl, magnuson, \n","       microdata, nas, ncr, nixdorf, perkin-elmer, prime, siemens, sperry, \n","       sratus, wang)\n","2. Model Name: many unique symbols\n","3. MYCT: machine cycle time in nanoseconds (integer)\n","4. MMIN: minimum main memory in kilobytes (integer)\n","5. MMAX: maximum main memory in kilobytes (integer)\n","6. CACH: cache memory in kilobytes (integer)\n","7. CHMIN: minimum channels in units (integer)\n","8. CHMAX: maximum channels in units (integer)\n","\n","Target \n","\n","9. PRP: published relative performance (integer)\n","10. ERP: estimated relative performance from the original article (integer)\n","\n","\n","Perform a regression using ANNs on the 1-8 features and compare your results with each of the target values. \n"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T20:15:38.670894Z","iopub.status.busy":"2024-05-08T20:15:38.670447Z","iopub.status.idle":"2024-05-08T20:15:40.078049Z","shell.execute_reply":"2024-05-08T20:15:40.076498Z","shell.execute_reply.started":"2024-05-08T20:15:38.670863Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-1.2403,  1.4201,  0.3916,  ..., -0.5159, -0.5472, -0.5159],\n","        [-1.3723,  0.4312, -0.3738,  ...,  3.1823,  0.6599,  2.3147],\n","        [ 0.4755,  1.2325, -0.5925,  ...,  0.0201,  0.3150, -0.0278],\n","        ...,\n","        [-0.0525,  0.8574, -0.2645,  ..., -0.4087, -0.5472,  0.1674],\n","        [ 1.2674, -0.6259, -0.1916,  ..., -0.1943, -0.5472, -0.1254],\n","        [ 0.2115, -1.2056,  3.2346,  ..., -0.6231, -0.5472, -0.7599]])\n","Epoch [100/1000], Loss: 13.9825\n","Epoch [200/1000], Loss: 11.6949\n","Epoch [300/1000], Loss: 9.6607\n","Epoch [400/1000], Loss: 8.2912\n","Epoch [500/1000], Loss: 7.1605\n","Epoch [600/1000], Loss: 6.2750\n","Epoch [700/1000], Loss: 5.3828\n","Epoch [800/1000], Loss: 5.0610\n","Epoch [900/1000], Loss: 4.4102\n","Epoch [1000/1000], Loss: 4.2909\n","tensor([[332.7304, 102.7241],\n","        [ 25.2158,  24.5428],\n","        [ 15.6947,  23.8827],\n","        [287.8379, 523.5867],\n","        [ 19.8373,  33.6080]])\n","tensor([[274., 102.],\n","        [ 30.,  25.],\n","        [ 22.,  25.],\n","        [915., 919.],\n","        [ 16.,  34.]])\n","Test Loss: 36.6205\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n","\n","# worse horrible when x is not scaled\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# works worse when y is scaled\n","# scaler2 = StandardScaler()\n","# y_train = scaler2.fit_transform(y_train)\n","# y_test = scaler2.fit_transform(y_test)\n","\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","y_train = torch.tensor(y_train.values, dtype=torch.float32) \n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_test = torch.tensor(y_test.values, dtype=torch.float32) \n","print(X_train)\n","\n","class RegressionModel(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(RegressionModel, self).__init__()\n","        self.hidden1 = nn.Linear(input_size, 64) \n","        self.hidden2 = nn.Linear(64, 32)\n","        self.output_layer = nn.Linear(32, output_size)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.hidden1(x))\n","        x = torch.relu(self.hidden2(x))\n","        output = torch.relu(self.output_layer(x))\n","        return output\n","\n","input_size = X_train.shape[1]\n","output_size = y_train.shape[1]\n","model = RegressionModel(input_size, output_size)\n","\n","criterion = nn.L1Loss() # this is MAE\n","optimizer = optim.Adam(model.parameters(), lr=0.01)  \n","\n","num_epochs = 1000\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    output = model(X_train)\n","    loss = criterion(output, y_train)\n","    loss.backward()\n","    optimizer.step()\n","    if (epoch + 1) % 100 == 0:\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","\n","with torch.no_grad():\n","    test_output = model(X_test)\n","#     test_output = torch.tensor(scaler2.inverse_transform(test_output.numpy()))\n","#     y_test_tensor = torch.tensor(scaler2.inverse_transform(y_test_tensor.numpy()))\n","    print(test_output[0:5])\n","    print(y_test[0:5])\n","    test_loss = criterion(test_output, y_test)\n","    print(f\"Test Loss: {test_loss.item():.4f}\")\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"nteract":{"version":"nteract-front-end@1.0.0"}},"nbformat":4,"nbformat_minor":4}
