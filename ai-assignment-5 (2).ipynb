{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## A.I. Assignment 5\n\n## Learning Goals\n\nBy the end of this lab, you should be able to:\n* Get more familiar with tensors in pytorch \n* Create a simple multilayer perceptron model with pytorch\n* Visualise the parameters\n\n\n### Task\n\nBuild a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n\nCreate at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n\nDisplay for the best one the weights for each layer.\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom collections import OrderedDict\nfrom sklearn.metrics import accuracy_score\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T13:47:33.279285Z","iopub.execute_input":"2024-04-05T13:47:33.279863Z","iopub.status.idle":"2024-04-05T13:47:34.980749Z","shell.execute_reply.started":"2024-04-05T13:47:33.279833Z","shell.execute_reply":"2024-04-05T13:47:34.979506Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# your code here\n#model1 = nn.Sequential(OrderedDict([\n#    ('hidden', nn.\n#]))\n\n\nclass Network1(torch.nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(Network1, self).__init__()\n        self.model_stack = nn.Sequential(OrderedDict([\n    ('hidden', nn.Linear(2, 5)), \n    ('la1', nn.ReLU()),\n    ('hidden2', nn.Linear(5, 2)),\n    ('la2', nn.Sigmoid())\n]))\n    def forward(self, x):\n        x = self.model_stack(x)\n        return x\n\n\nclass Network2(torch.nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(Network2, self).__init__()\n        self.model_stack = nn.Sequential(OrderedDict([\n    ('hidden', nn.Linear(2, 5)), \n    ('la1', nn.LeakyReLU()),\n    ('hidden2', nn.Linear(5, 2)),\n    ('la2', nn.Sigmoid())\n]))\n    def forward(self, x):\n        x = self.model_stack(x)\n        return x\n    \n    \nclass Network3(torch.nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(Network3, self).__init__()\n        self.model_stack = nn.Sequential(OrderedDict([\n    ('hidden', nn.Linear(2, 100)), \n    ('la1', nn.ReLU()),\n    ('hidden2', nn.Linear(100, 2)),\n    ('la3', nn.Sigmoid())\n]))\n    def forward(self, x):\n        x = self.model_stack(x)\n        return x\n            \nmodel1 = Network1(None, None)\nmodel2 = Network2(None, None)\nmodel3 = Network3(None, None)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:03:54.310154Z","iopub.execute_input":"2024-04-05T14:03:54.311339Z","iopub.status.idle":"2024-04-05T14:03:54.323696Z","shell.execute_reply.started":"2024-04-05T14:03:54.311304Z","shell.execute_reply":"2024-04-05T14:03:54.322864Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(model1)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T16:51:13.182803Z","iopub.execute_input":"2024-03-27T16:51:13.183270Z","iopub.status.idle":"2024-03-27T16:51:13.191633Z","shell.execute_reply.started":"2024-03-27T16:51:13.183235Z","shell.execute_reply":"2024-03-27T16:51:13.189764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# your code here\n#data_in = torch.tensor( ...\ndata_in = torch.tensor([[0,0],\n                       [0,1],\n                       [0,1],\n                        [1,0]]\n                      ).float()\nprint(data_in)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:03:56.732518Z","iopub.execute_input":"2024-04-05T14:03:56.733061Z","iopub.status.idle":"2024-04-05T14:03:56.740527Z","shell.execute_reply.started":"2024-04-05T14:03:56.733026Z","shell.execute_reply":"2024-04-05T14:03:56.739406Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"tensor([[0., 0.],\n        [0., 1.],\n        [0., 1.],\n        [1., 0.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# your code here\n# data_target = torch.tensor( ...\ndata_target = torch.tensor([[0,0],\n                          [0,1],\n                          [0,1],\n                          [1,0]]).float()\nprint(data_target)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:03:58.529769Z","iopub.execute_input":"2024-04-05T14:03:58.530189Z","iopub.status.idle":"2024-04-05T14:03:58.538010Z","shell.execute_reply.started":"2024-04-05T14:03:58.530160Z","shell.execute_reply":"2024-04-05T14:03:58.536856Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"tensor([[0., 0.],\n        [0., 1.],\n        [0., 1.],\n        [1., 0.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# your code here\ncriterion = nn.MSELoss()  \noptimizer1 = torch.optim.SGD(model1.parameters(), lr=0.1)\noptimizer2 = torch.optim.SGD(model2.parameters(), lr=0.1)\noptimizer3 = torch.optim.SGD(model3.parameters(), lr=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:04:01.412911Z","iopub.execute_input":"2024-04-05T14:04:01.413298Z","iopub.status.idle":"2024-04-05T14:04:01.421150Z","shell.execute_reply.started":"2024-04-05T14:04:01.413271Z","shell.execute_reply":"2024-04-05T14:04:01.419804Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# your code here\n# Train model 1\nimport numpy as np\n\nnum_epochs = 10000\nfor epoch in range(num_epochs):\n    outputs = model1(data_in)\n    accuracy = accuracy_score(outputs.detach().round(), data_target.detach().round())\n    if accuracy == 1:\n        print(f'Accuracy 1 after {epoch} epochs')\n        break;\n        \n    loss = criterion(outputs, data_target)\n    \n    optimizer1.zero_grad()\n    loss.backward()\n    optimizer1.step()\n\n    if (epoch + 1) % 1000 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:04:03.662019Z","iopub.execute_input":"2024-04-05T14:04:03.662410Z","iopub.status.idle":"2024-04-05T14:04:03.785277Z","shell.execute_reply.started":"2024-04-05T14:04:03.662378Z","shell.execute_reply":"2024-04-05T14:04:03.784448Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Accuracy 1 after 59 epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"#train model 2\nnum_epochs = 10000\nfor epoch in range(num_epochs):\n    outputs = model2(data_in)\n    accuracy = accuracy_score(outputs.detach().round(), data_target.detach().round())\n    if accuracy == 1:\n        print(f'Accuracy 1 after {epoch} epochs')\n        break;\n        \n    loss = criterion(outputs, data_target)\n\n    optimizer2.zero_grad()\n    loss.backward()\n    optimizer2.step()\n\n    if (epoch + 1) % 1000 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:04:09.964265Z","iopub.execute_input":"2024-04-05T14:04:09.964620Z","iopub.status.idle":"2024-04-05T14:04:11.918967Z","shell.execute_reply.started":"2024-04-05T14:04:09.964595Z","shell.execute_reply":"2024-04-05T14:04:11.917584Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Accuracy 1 after 976 epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"#train model 3\nnum_epochs = 10000\nfor epoch in range(num_epochs):\n    outputs = model3(data_in)\n    accuracy = accuracy_score(outputs.detach().round(), data_target.detach().round())\n    if accuracy == 1:\n        print(f'Accuracy 1 after {epoch} epochs')\n        break;\n        \n    loss = criterion(outputs, data_target)\n\n    optimizer3.zero_grad()\n    loss.backward()\n    optimizer3.step()\n\n    if (epoch + 1) % 1000 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:04:14.422546Z","iopub.execute_input":"2024-04-05T14:04:14.423765Z","iopub.status.idle":"2024-04-05T14:04:14.467705Z","shell.execute_reply.started":"2024-04-05T14:04:14.423718Z","shell.execute_reply":"2024-04-05T14:04:14.466564Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Accuracy 1 after 15 epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"# your code here\n# visualize the resuts\nprint(data_in)\nprint(model1(data_in))\nprint(model2(data_in))\nprint(model3(data_in))","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:15:36.862103Z","iopub.execute_input":"2024-04-05T14:15:36.862524Z","iopub.status.idle":"2024-04-05T14:15:36.873155Z","shell.execute_reply.started":"2024-04-05T14:15:36.862498Z","shell.execute_reply":"2024-04-05T14:15:36.871805Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"tensor([[0., 0.],\n        [0., 1.],\n        [0., 1.],\n        [1., 0.]])\ntensor([[0.4175, 0.4997],\n        [0.4130, 0.5272],\n        [0.4130, 0.5272],\n        [0.5035, 0.4178]], grad_fn=<SigmoidBackward0>)\ntensor([[0.3644, 0.2535],\n        [0.0334, 0.9256],\n        [0.0334, 0.9256],\n        [0.5001, 0.1428]], grad_fn=<SigmoidBackward0>)\ntensor([[0.3943, 0.4995],\n        [0.2652, 0.6017],\n        [0.2652, 0.6017],\n        [0.5052, 0.4781]], grad_fn=<SigmoidBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"# your code here\n# print model weights\nfor param in model1.parameters():\n    print(param)\nfor param in model2.parameters():\n    print(param)\nfor param in model3.parameters():\n    print(param)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T19:43:02.316144Z","iopub.execute_input":"2024-04-01T19:43:02.316555Z","iopub.status.idle":"2024-04-01T19:43:02.333917Z","shell.execute_reply.started":"2024-04-01T19:43:02.316521Z","shell.execute_reply":"2024-04-01T19:43:02.332906Z"},"trusted":true},"execution_count":154,"outputs":[{"name":"stdout","text":"Parameter containing:\ntensor([[-0.8885,  2.0234],\n        [ 1.9998, -1.5329],\n        [ 1.4750, -0.5849],\n        [-0.0865, -0.4637],\n        [-2.1092, -2.1093],\n        [-1.6608, -0.0469],\n        [ 1.8237,  0.7522],\n        [-1.4053,  2.2837],\n        [-0.8191,  1.9239],\n        [-1.4352,  1.4568]], requires_grad=True)\nParameter containing:\ntensor([ 0.2145,  1.5329,  0.2308, -0.3576,  2.1092,  1.9102, -0.0106,  1.0019,\n         0.0591,  0.9581], requires_grad=True)\nParameter containing:\ntensor([[-1.6874,  1.5971,  1.5327, -0.2292, -2.3077, -1.7325,  1.5409, -1.6851,\n         -0.9558, -1.8339],\n        [ 1.9401, -2.1650, -0.8163,  0.3100, -1.8366, -1.5012, -0.0245,  1.3867,\n          2.1957,  0.7104]], requires_grad=True)\nParameter containing:\ntensor([-0.6806, -1.9704], requires_grad=True)\nParameter containing:\ntensor([[ 2.2479, -2.7492],\n        [-3.0371,  2.4990],\n        [ 3.5265, -0.2488],\n        [ 2.3959, -3.4450],\n        [ 3.1163, -0.3567]], requires_grad=True)\nParameter containing:\ntensor([ 1.8197e+00,  2.2111e+00, -1.4075e-05,  1.5863e+00, -3.9680e+00],\n       requires_grad=True)\nParameter containing:\ntensor([[ 0.1173, -3.5304,  2.6524,  0.4755,  3.8408],\n        [-2.8038,  2.4052, -1.6339, -5.6563,  2.2445]], requires_grad=True)\nParameter containing:\ntensor([-2.1241, -1.3670], requires_grad=True)\nParameter containing:\ntensor([[-1.2554e+00,  1.2477e+00],\n        [-1.1198e+00,  1.1107e+00],\n        [-3.0913e-01,  4.5076e-01],\n        [-5.9388e-01,  1.5958e+00],\n        [-3.8505e-01, -2.1234e-01],\n        [-3.2298e-01,  9.7758e-01],\n        [ 7.4670e-01, -1.4287e+00],\n        [-2.3041e-01,  1.4169e+00],\n        [-6.7431e-01, -4.7240e-01],\n        [ 1.6355e+00, -4.1742e-01],\n        [ 1.1291e+00, -8.4657e-01],\n        [ 4.3012e-01, -5.5232e-01],\n        [ 1.6044e-02, -1.3309e-01],\n        [ 1.0480e+00, -5.1033e-01],\n        [ 9.1887e-02, -6.6111e-01],\n        [ 1.0380e+00, -1.8599e-01],\n        [-9.5592e-01,  1.0759e+00],\n        [-9.0365e-03,  4.3904e-02],\n        [ 1.0674e+00, -1.4509e+00],\n        [-1.1568e+00,  8.9330e-01],\n        [-1.0074e+00,  1.2532e+00],\n        [ 5.7828e-02, -6.7346e-01],\n        [ 6.2408e-01,  8.9753e-01],\n        [-5.1036e-01,  1.1760e+00],\n        [-2.1921e-01, -1.7546e-01],\n        [-2.2523e-01, -2.9202e-01],\n        [-1.4096e-01,  8.7845e-02],\n        [ 1.4462e+00, -2.6622e-01],\n        [-4.2496e-01,  1.4605e+00],\n        [ 1.4616e+00, -4.5835e-01],\n        [-5.5314e-01, -4.0449e-01],\n        [ 1.1091e+00, -1.4828e+00],\n        [-2.5074e-01,  7.6429e-02],\n        [-9.8123e-02,  7.9582e-02],\n        [-1.2355e+00,  3.0441e-01],\n        [ 1.8821e-01, -7.7723e-02],\n        [ 2.0416e-01,  1.0745e-01],\n        [-9.4502e-01, -1.0834e+00],\n        [-1.3335e+00, -6.0012e-01],\n        [-8.7097e-01,  3.6018e-01],\n        [-9.6958e-01,  1.2116e+00],\n        [-5.1074e-01, -4.3754e-01],\n        [ 3.8579e-01, -8.9712e-01],\n        [-2.0024e-01, -5.2266e-01],\n        [ 2.0107e-01, -1.3092e-01],\n        [-9.4440e-02,  1.6536e+00],\n        [ 1.1658e+00, -4.5839e-01],\n        [-8.9104e-01, -1.0707e+00],\n        [-3.5919e-01, -3.4716e-01],\n        [ 1.1986e+00, -8.3591e-01],\n        [-8.2289e-01,  1.3272e+00],\n        [-2.8453e-01, -2.9739e-01],\n        [-2.5594e-01,  4.6899e-01],\n        [-7.7843e-01, -1.6908e+00],\n        [-1.1222e-01,  8.0485e-01],\n        [-4.4200e-01,  4.6428e-01],\n        [-5.1541e-01, -6.2396e-01],\n        [-2.1903e-01, -5.4526e-02],\n        [-4.8429e-02, -5.2417e-01],\n        [ 1.5891e-01, -6.2565e-01],\n        [-4.8362e-01,  4.4570e-02],\n        [-1.0476e+00,  1.2147e+00],\n        [ 1.3427e+00, -3.6330e-01],\n        [-1.5476e-01,  1.1888e-01],\n        [-9.5721e-02, -5.1351e-02],\n        [ 1.6805e-01, -6.4295e-01],\n        [-3.8506e-01,  1.0669e+00],\n        [-1.8884e-01,  1.4313e+00],\n        [ 1.4884e+00, -5.2857e-01],\n        [-6.8993e-01, -3.4855e-04],\n        [-7.2089e-01,  1.0852e+00],\n        [-2.8088e-01,  1.3011e-01],\n        [-4.1737e-01,  1.5954e-01],\n        [-1.0746e+00,  9.6242e-01],\n        [ 9.1925e-02, -4.3637e-01],\n        [-1.2021e+00, -6.3701e-01],\n        [-1.6861e-01, -1.6276e-01],\n        [-7.5949e-01,  3.4782e-02],\n        [ 7.7710e-01, -1.2615e+00],\n        [-6.6720e-01, -2.5045e-01],\n        [-1.4240e+00, -1.2248e+00],\n        [-1.1894e+00,  1.2571e+00],\n        [-7.4725e-01,  3.7571e-01],\n        [ 7.7310e-01, -1.3810e+00],\n        [-5.7112e-01,  1.4031e+00],\n        [ 9.1663e-01, -6.6459e-01],\n        [-4.7371e-01, -5.3648e-01],\n        [-5.4496e-01, -6.0843e-01],\n        [-6.2852e-01,  1.6446e+00],\n        [-1.9073e-01, -1.2564e-01],\n        [-1.1686e+00, -8.7374e-01],\n        [ 4.0402e-01, -1.0161e+00],\n        [ 1.0947e+00, -1.2002e+00],\n        [-7.4241e-01,  1.6210e+00],\n        [ 1.9549e-01, -4.5438e-01],\n        [-3.9812e-01,  1.3955e+00],\n        [ 9.6864e-02, -6.8610e-01],\n        [ 7.1670e-01,  1.0223e-01],\n        [-6.5618e-01, -4.3081e-01],\n        [-5.2908e-01, -7.6222e-01]], requires_grad=True)\nParameter containing:\ntensor([ 0.6941,  1.1238,  1.5587, -0.3392, -0.1991, -0.1350,  0.9348, -0.7292,\n        -0.0699,  0.3842,  0.3795, -0.5974, -0.6394,  0.2595, -0.5383, -0.0071,\n         0.9693, -0.5206,  0.8794,  0.7261,  1.1190, -0.1077, -0.3797, -0.3373,\n        -0.2848, -0.2297, -1.1073, -0.0889, -0.1883,  0.1018, -0.0465,  1.0441,\n        -0.3073, -0.3046,  1.4296,  0.2769, -0.9398,  1.3592,  1.7089,  0.8556,\n         0.1881, -0.3261,  0.6145, -0.4971, -0.4181, -0.6854,  0.3513,  1.3276,\n        -0.5426, -0.1217,  0.4986,  0.4543, -0.5561,  1.5177, -0.5152, -0.6920,\n         0.9179, -0.3452, -0.5998, -0.2051, -0.6056,  1.1254,  0.1974, -0.4311,\n        -0.8273, -0.3043,  0.2442,  0.1888,  0.1143, -0.6928,  0.8391, -0.4647,\n        -0.6268,  0.5915, -0.2060,  1.4627, -0.4438,  1.6418,  0.8469, -0.0275,\n         1.6035,  0.7587,  0.8000,  1.1137, -0.3881,  0.2445, -0.5006, -0.5305,\n         0.8732, -0.9160,  1.2450,  0.7771,  0.6925,  1.0929, -0.5854,  0.6216,\n        -0.4850, -0.7607, -0.2252,  0.3190], requires_grad=True)\nParameter containing:\ntensor([[-0.7804, -1.0842,  0.0158, -0.6040, -0.0519, -0.2659,  0.3278,  0.3643,\n         -0.0864,  1.0730,  0.4431, -0.0732, -0.0312,  0.9375, -0.0619,  0.7037,\n         -0.8705, -0.0600,  0.5063, -0.7198, -1.0426, -0.0583,  0.7732, -0.1804,\n         -0.0261, -0.5201, -0.4589,  1.0208, -0.5045,  1.0317,  0.0394,  0.4884,\n          0.0507,  0.0297, -0.8675, -0.4198, -0.5652, -1.0858, -1.1502, -0.3246,\n         -0.6023,  0.0514, -0.0077, -0.0109, -0.1641, -0.2418,  0.8509, -1.3510,\n         -0.0894,  0.9302, -0.5224, -0.0156,  0.0229, -0.1146,  0.7268, -0.0239,\n          0.0294,  0.0640, -0.5658, -0.0020, -0.5837, -0.8765,  0.9289,  0.0185,\n         -0.1589, -0.0441,  0.0215, -0.6469,  0.9799, -0.0518, -0.6163, -0.5309,\n         -0.0435, -0.7281, -0.0240, -0.9082,  0.0756, -0.2232,  0.3178, -0.0786,\n         -1.3916, -0.8102, -0.6446, -0.0368, -0.5962,  0.2822, -0.5389, -0.0956,\n         -0.6083,  0.5838, -1.2643, -0.0414,  0.5077, -0.7291,  0.3475, -0.5897,\n         -0.0738,  0.0936, -0.0867, -0.7204],\n        [ 0.4712,  0.8310, -0.7732,  0.6679, -0.0050,  0.2344, -1.0260,  0.4890,\n          0.0435, -0.8010, -0.9629, -0.0527,  0.0858, -0.7455,  0.0679, -0.5745,\n          0.7543,  0.0695, -0.9424,  0.0328,  0.8997, -0.0783, -0.4671,  0.3865,\n         -0.0173, -0.5810,  0.4905, -0.7944,  0.7264, -0.9524, -0.1358, -1.0078,\n          0.0427, -0.0387, -0.7851,  0.1934,  0.5824, -0.9508, -0.2028, -0.7206,\n          0.4407, -0.0244, -0.7438,  0.0386,  0.2570,  1.0748, -0.7925, -0.8791,\n         -0.0881, -0.8139,  0.3163, -0.4164, -0.0844, -0.9659, -0.2076,  0.0627,\n         -0.7579, -0.0313, -0.5990, -0.0826,  0.5799,  0.6018, -0.8581,  0.0924,\n          0.3515,  0.0121, -0.2015,  0.8337, -0.8705, -0.0854,  0.6437,  0.6350,\n         -0.0448,  0.1020,  0.0749,  0.0356,  0.0641, -0.8696, -0.9833, -0.0699,\n         -1.0138,  0.4111,  0.5664, -1.0057,  0.6471, -0.9730, -0.5221, -0.0445,\n          0.7796, -0.5102, -0.7685, -0.9511, -0.9325,  0.6797, -0.3924,  0.8130,\n          0.0992,  0.3672, -0.0879, -0.7821]], requires_grad=True)\nParameter containing:\ntensor([-0.4836, -0.3485], requires_grad=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}